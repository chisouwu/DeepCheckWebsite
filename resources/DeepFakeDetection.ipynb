{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NtQv-E1LrJ-A"
   },
   "source": [
    "**Spartahack X** ![spartahackXlogo.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1bwBxJPScSdq",
    "outputId": "725bfe9a-83c0-44f6-f04e-2cfe2e151865"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.0.2)\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.18.0-cp311-cp311-win_amd64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: kaggle in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.6.17)\n",
      "Requirement already satisfied: joblib in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.4.2)\n",
      "Collecting librosa\n",
      "  Downloading librosa-0.10.2.post1-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2024.2)\n",
      "Collecting tensorflow-intel==2.18.0 (from tensorflow)\n",
      "  Using cached tensorflow_intel-2.18.0-cp311-cp311-win_amd64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (5.28.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.67.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from kaggle) (2024.8.30)\n",
      "Requirement already satisfied: tqdm in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from kaggle) (2.2.3)\n",
      "Requirement already satisfied: bleach in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from kaggle) (6.2.0)\n",
      "Collecting audioread>=2.1.9 (from librosa)\n",
      "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from librosa) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from librosa) (1.5.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from librosa) (5.1.1)\n",
      "Collecting numba>=0.51.0 (from librosa)\n",
      "  Downloading numba-0.61.0-cp311-cp311-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting soundfile>=0.12.1 (from librosa)\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-win_amd64.whl.metadata (16 kB)\n",
      "Collecting pooch>=1.1 (from librosa)\n",
      "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa)\n",
      "  Downloading soxr-0.5.0.post1-cp311-cp311-win_amd64.whl.metadata (5.6 kB)\n",
      "Collecting lazy-loader>=0.1 (from librosa)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting msgpack>=1.0 (from librosa)\n",
      "  Downloading msgpack-1.1.0-cp311-cp311-win_amd64.whl.metadata (8.6 kB)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba>=0.51.0->librosa)\n",
      "  Downloading llvmlite-0.44.0-cp311-cp311-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pooch>=1.1->librosa) (4.3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm->kaggle) (0.4.6)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "Requirement already satisfied: rich in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\tyoneyam\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n",
      "Using cached tensorflow-2.18.0-cp311-cp311-win_amd64.whl (7.5 kB)\n",
      "Using cached tensorflow_intel-2.18.0-cp311-cp311-win_amd64.whl (390.2 MB)\n",
      "Downloading librosa-0.10.2.post1-py3-none-any.whl (260 kB)\n",
      "   ---------------------------------------- 0.0/260.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 260.1/260.1 kB 8.1 MB/s eta 0:00:00\n",
      "Downloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading msgpack-1.1.0-cp311-cp311-win_amd64.whl (74 kB)\n",
      "   ---------------------------------------- 0.0/74.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 74.9/74.9 kB 4.0 MB/s eta 0:00:00\n",
      "Downloading numba-0.61.0-cp311-cp311-win_amd64.whl (2.8 MB)\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.7/2.8 MB 20.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.7/2.8 MB 21.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.7/2.8 MB 21.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.8/2.8 MB 18.1 MB/s eta 0:00:00\n",
      "Downloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "   ---------------------------------------- 0.0/64.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 64.6/64.6 kB 3.4 MB/s eta 0:00:00\n",
      "Downloading soundfile-0.13.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 21.5 MB/s eta 0:00:00\n",
      "Downloading soxr-0.5.0.post1-cp311-cp311-win_amd64.whl (166 kB)\n",
      "   ---------------------------------------- 0.0/166.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 166.7/166.7 kB 10.4 MB/s eta 0:00:00\n",
      "Downloading llvmlite-0.44.0-cp311-cp311-win_amd64.whl (30.3 MB)\n",
      "   ---------------------------------------- 0.0/30.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.1/30.3 MB 34.4 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 2.4/30.3 MB 25.5 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 3.7/30.3 MB 26.6 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 5.1/30.3 MB 27.0 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 6.4/30.3 MB 27.4 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 8.0/30.3 MB 28.4 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 9.1/30.3 MB 26.6 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 10.2/30.3 MB 27.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 11.3/30.3 MB 26.2 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 12.3/30.3 MB 25.2 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 13.0/30.3 MB 24.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 13.9/30.3 MB 22.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 15.2/30.3 MB 22.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 16.4/30.3 MB 21.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 17.8/30.3 MB 21.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 18.8/30.3 MB 21.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 20.1/30.3 MB 22.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 21.0/30.3 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 21.8/30.3 MB 21.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 22.4/30.3 MB 21.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 23.0/30.3 MB 19.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 23.5/30.3 MB 21.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 24.2/30.3 MB 19.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 24.8/30.3 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 25.4/30.3 MB 18.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 26.0/30.3 MB 17.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 26.8/30.3 MB 16.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 27.8/30.3 MB 16.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 28.6/30.3 MB 16.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 29.3/30.3 MB 15.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  30.3/30.3 MB 14.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  30.3/30.3 MB 14.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 30.3/30.3 MB 13.1 MB/s eta 0:00:00\n",
      "Installing collected packages: soxr, msgpack, llvmlite, lazy-loader, audioread, soundfile, pooch, numba, librosa, tensorflow-intel, tensorflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\tyoneyam\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python311\\\\site-packages\\\\tensorflow\\\\include\\\\external\\\\com_github_grpc_grpc\\\\src\\\\core\\\\ext\\\\filters\\\\client_channel\\\\lb_policy\\\\grpclb\\\\client_load_reporting_filter.h'\n",
      "HINT: This error might have occurred since this system does not have Windows Long Path support enabled. You can find information on how to enable this at https://pip.pypa.io/warnings/enable-long-paths\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0\n",
      "[notice] To update, run: C:\\Users\\tyoneyam\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy tensorflow kaggle joblib librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "7acEWvTBqc1j",
    "outputId": "00ab8887-9670-421c-f910-6a67a4887ccb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-5971616f-f2d8-4e8b-87ff-affdfd6c21a7\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-5971616f-f2d8-4e8b-87ff-affdfd6c21a7\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving kaggle.json to kaggle.json\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "# Upload kaggle.json\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uL86sGITqrfu",
    "outputId": "9c29e155-cb0c-43f5-f641-6130e623ac39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref                                                              title                                               size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
      "---------------------------------------------------------------  -------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
      "birdy654/deep-voice-deepfake-voice-recognition                   DEEP-VOICE: DeepFake Voice Recognition               4GB  2023-08-24 13:12:23           7643         80  1.0              \n",
      "manjilkarki/deepfake-and-real-images                             deepfake and real images                             2GB  2022-02-03 15:33:45          16104         73  0.625            \n",
      "dagnelies/deepfake-faces                                         deepfake_faces                                     433MB  2020-02-02 19:44:24           6276         80  0.5882353        \n",
      "khoongweihao/deepfake-xception-trained-model                     Deepfake Xception Trained Model                    467MB  2020-02-25 01:12:29            889         19  0.8125           \n",
      "unkownhihi/deepfake                                              DeepFake(150*150)                                  763MB  2020-01-15 22:28:29            952         33  0.375            \n",
      "khoongweihao/deepfake-kernel-data                                Deepfake Kernel Data                                78MB  2020-02-28 13:47:55            188          8  0.8125           \n",
      "abdallamohamed312/in-the-wild-audio-deepfake                     In The Wild (audio Deepfake)                          0B  2024-04-20 04:28:55            586         42  1.0              \n",
      "robikscube/deepfakemodelspackages                                deepfake-models-packages                           560MB  2019-12-16 16:32:12            588         30  0.375            \n",
      "vlbthambawita/deepfake-ecg                                       DeepFake ECG                                        15GB  2021-05-27 20:47:05            297         20  0.8235294        \n",
      "ymirsky/medical-deepfakes-lung-cancer                            Medical Deepfakes: Lung Cancer                       6GB  2020-04-23 17:50:12           3375         53  0.7941176        \n",
      "phunghieu/deepfake-detection-faces-part-0-0                      Deepfake Detection - Faces - Part 0_0                4GB  2020-02-04 03:08:49           1203         39  0.8235294        \n",
      "humananalog/deepfakes-inference-demo                             Deepfakes Inference Demo                            81MB  2020-01-21 12:51:52           2356         40  0.5              \n",
      "phunghieu/deepfake-detection-logistic-regression                 Deepfake Detection - Logistic Regression            567B  2020-03-05 00:26:34           1123         17  1.0              \n",
      "mohammedabdeldayem/the-fake-or-real-dataset                      The Fake-or-Real (FoR) Dataset (deepfake audio)     16GB  2024-04-16 01:54:50           2055         34  0.75             \n",
      "peilwang/deepfake                                                deepfake                                            23GB  2024-07-03 08:31:00            447          7  0.1875           \n",
      "phunghieu/deepfake-detection-faces-part-3-0                      Deepfake Detection - Faces - Part 3_0                5GB  2020-02-04 10:12:43            167         17  0.8235294        \n",
      "sanikatiwarekar/deep-fake-detection-dfd-entire-original-dataset  Deep Fake Detection (DFD) Entire Original Dataset   22GB  2024-08-10 11:48:58           2746         32  0.8125           \n",
      "phunghieu/deepfake-detection-faces-part-0-1                      Deepfake Detection - Faces - Part 0_1                4GB  2020-02-06 13:35:30            216         20  0.8235294        \n",
      "mohammedabdeldayem/avsspoof-2021                                 ASVspoof 2021 Dataset                               58GB  2024-05-18 17:40:31            410         23  0.875            \n",
      "aleksandrpikul222/dfdcdfdc                                       DFDCDFDC (100k DeepFakes)                           10GB  2024-01-03 19:38:36            339          4  1.0              \n",
      "Dataset URL: https://www.kaggle.com/datasets/birdy654/deep-voice-deepfake-voice-recognition\n",
      "License(s): other\n",
      "Downloading deep-voice-deepfake-voice-recognition.zip to /content\n",
      "100% 3.68G/3.69G [00:48<00:00, 108MB/s]\n",
      "100% 3.69G/3.69G [00:48<00:00, 81.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Create the .kaggle directory\n",
    "!mkdir -p ~/.kaggle\n",
    "\n",
    "# Move kaggle.json to the .kaggle directory\n",
    "!mv kaggle.json ~/.kaggle/\n",
    "\n",
    "# Set permissions to secure the API key\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "!kaggle datasets download -d birdy654/deep-voice-deepfake-voice-recognition --unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-KmarwJ5fjxC",
    "outputId": "e757d4af-c65f-45b5-e41c-05e9fb421372"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   chroma_stft       rms  spectral_centroid  spectral_bandwidth      rolloff  \\\n",
      "0     0.338055  0.027948        2842.948867         4322.916759  6570.586186   \n",
      "1     0.443766  0.037838        2336.129597         3445.777044  3764.949874   \n",
      "2     0.302528  0.056578        2692.988386         2861.133180  4716.610271   \n",
      "3     0.319933  0.031504        2241.665382         3503.766175  3798.641521   \n",
      "4     0.420055  0.016158        2526.069123         3102.659519  5025.077899   \n",
      "\n",
      "   zero_crossing_rate       mfcc1       mfcc2      mfcc3      mfcc4  ...  \\\n",
      "0            0.041050 -462.169586   90.311272  19.073769  24.046888  ...   \n",
      "1            0.047730 -409.413422  120.348808  -7.161531   5.114784  ...   \n",
      "2            0.080342 -318.996033  120.490273 -24.625771  23.891073  ...   \n",
      "3            0.047180 -404.636749  136.320908   2.308172  -3.907071  ...   \n",
      "4            0.051905 -410.497925  152.731400 -18.266771  51.993462  ...   \n",
      "\n",
      "     mfcc12    mfcc13    mfcc14    mfcc15    mfcc16    mfcc17    mfcc18  \\\n",
      "0 -6.686564  0.902086 -7.251551 -1.198342  4.747403 -4.986279  0.953935   \n",
      "1 -2.131157 -6.876417 -1.359395  0.326401 -5.420016 -2.109968 -1.757634   \n",
      "2 -5.853725 -3.724773 -6.627182 -5.117002 -6.072106 -0.994653 -1.617120   \n",
      "3 -1.898315 -2.046493 -7.176277 -3.293508  4.209121  0.121835 -5.407063   \n",
      "4 -1.952340  0.810868  6.238493  6.555839  7.535542  2.849219  2.616843   \n",
      "\n",
      "     mfcc19    mfcc20  LABEL  \n",
      "0 -5.013138 -6.779060   FAKE  \n",
      "1 -9.537907 -8.494421   FAKE  \n",
      "2 -3.922354 -7.033001   FAKE  \n",
      "3 -3.654926 -3.274857   FAKE  \n",
      "4 -1.793357 -5.060998   FAKE  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "Training set: 7537 samples\n",
      "Validation set: 1885 samples\n",
      "Test set: 2356 samples\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# for root, dirs, files in os.walk(\".\"):\n",
    "#      for file in files:\n",
    "#          print(os.path.join(root, file))\n",
    "\n",
    "df = pd.read_csv(\"./KAGGLE/DATASET-balanced.csv\")\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming df is your DataFrame and \"LABEL\" is the target column\n",
    "X = df.drop(columns=[\"LABEL\"])  # Features\n",
    "y = df[\"LABEL\"]  # Target\n",
    "\n",
    "# First, split into training (80%) and temp (20%) for test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# If you also want a validation set, split train further\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print dataset sizes\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Validation set: {len(X_val)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k_4sA3OFcn4Z"
   },
   "source": [
    "**Train Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_3u0a7ki9HiV",
    "outputId": "584e2caa-0075-4a18-9007-4ff2e9ae6030"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9952254641909815\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       1.00      0.99      1.00       929\n",
      "        REAL       0.99      1.00      1.00       956\n",
      "\n",
      "    accuracy                           1.00      1885\n",
      "   macro avg       1.00      1.00      1.00      1885\n",
      "weighted avg       1.00      1.00      1.00      1885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC # Import the SVC class\n",
    "from sklearn.metrics import accuracy_score, classification_report # Import accuracy_score and classification_report\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training data and transform all splits\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Create SVM classifier with RBF kernel (good default choice)\n",
    "svm_model = SVC(kernel=\"rbf\", C=1.0, gamma=\"scale\", random_state=42)\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "y_val_pred = svm_model.predict(X_val)\n",
    "\n",
    "# Print accuracy\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "\n",
    "# Print detailed classification report\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNWvNpVB9RSi"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XC8yYVSu9Rou",
    "outputId": "89861291-3517-4f5c-9cb1-e2d10b7c6856"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9940577249575552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       1.00      0.99      0.99      1193\n",
      "        REAL       0.99      1.00      0.99      1163\n",
      "\n",
      "    accuracy                           0.99      2356\n",
      "   macro avg       0.99      0.99      0.99      2356\n",
      "weighted avg       0.99      0.99      0.99      2356\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Print accuracy\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3-rHrFcC52u"
   },
   "source": [
    "# Test Model on Generated DeepFakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "id": "4jYvk-RCYoOa",
    "outputId": "0abec444-87dc-4a05-b323-a6da8025348c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-c381bbfb-9524-48b9-a4d5-c9c39d69e9d6\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-c381bbfb-9524-48b9-a4d5-c9c39d69e9d6\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Alex-2025_01_30-1.wav to Alex-2025_01_30-1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The uploaded audio file is predicted to be: FAKE\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from google.colab import files\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from moviepy.editor import VideoFileClip\n",
    "import os\n",
    "\n",
    "# Function to extract features from an audio file\n",
    "def extract_features(file_path):\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "    # Extract features\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr).mean()\n",
    "    rms = librosa.feature.rms(y=y).mean()\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr).mean()\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr).mean()\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr).mean()\n",
    "    zero_crossing_rate = librosa.feature.zero_crossing_rate(y).mean()\n",
    "\n",
    "    # Extract MFCCs (20 coefficients)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
    "    mfcc_means = [np.mean(mfcc) for mfcc in mfccs]  # Mean of each MFCC coefficient\n",
    "\n",
    "    # Combine all features into a single array\n",
    "    features = np.hstack([\n",
    "        chroma_stft, rms, spectral_centroid, spectral_bandwidth, rolloff, zero_crossing_rate, *mfcc_means\n",
    "    ])\n",
    "\n",
    "    return features\n",
    "\n",
    "# Function to extract audio from MP4 and save as WAV\n",
    "def extract_audio_from_mp4(mp4_path, wav_path):\n",
    "    # Load the video file\n",
    "    video = VideoFileClip(mp4_path)\n",
    "\n",
    "    # Extract audio\n",
    "    audio = video.audio\n",
    "\n",
    "    # Save audio as WAV\n",
    "    audio.write_audiofile(wav_path)\n",
    "\n",
    "    # Close the video file\n",
    "    video.close()\n",
    "\n",
    "# Prompt the user to upload a file\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Get the file path of the uploaded file\n",
    "file_path = list(uploaded.keys())[0]\n",
    "\n",
    "# Check if the uploaded file is an MP4\n",
    "if file_path.endswith('.mp4'):\n",
    "    # Extract audio from MP4 and save as WAV\n",
    "    wav_path = file_path.replace('.mp4', '.wav')\n",
    "    extract_audio_from_mp4(file_path, wav_path)\n",
    "\n",
    "    # Use the extracted WAV file for feature extraction\n",
    "    file_path = wav_path\n",
    "\n",
    "# Extract features from the uploaded audio file\n",
    "features = extract_features(file_path)\n",
    "\n",
    "# Reshape the features to match the input shape of the model\n",
    "features = features.reshape(1, -1)\n",
    "\n",
    "# Scale the features using the same scaler used during training\n",
    "features_scaled = scaler.transform(features)\n",
    "\n",
    "# Predict using the trained SVM model\n",
    "prediction = svm_model.predict(features_scaled)\n",
    "\n",
    "# Output the prediction\n",
    "print(f\"The uploaded audio file is predicted to be: {prediction[0]}\")\n",
    "\n",
    "# Clean up: Remove the temporary WAV file if it was created\n",
    "if file_path.endswith('.wav') and os.path.exists(file_path):\n",
    "    os.remove(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wMf-JLApRQ3l"
   },
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "Ps8C3HBPRQgg",
    "outputId": "2082b698-96cf-48cd-c89a-74f7fdd24c0b"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_8ed35e52-6649-4d47-b75e-45225f3ddb9d\", \"svm_model.pkl\", 187062)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_cd1cbb4a-9115-4cd6-9654-5322085173b2\", \"scaler.pkl\", 1423)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prompt: Save the model as pkl\n",
    "\n",
    "import pickle\n",
    "# Save the model to a file\n",
    "filename = 'svm_model.pkl'\n",
    "pickle.dump(svm_model, open(filename, 'wb'))\n",
    "\n",
    "# Download the saved model file\n",
    "files.download(filename)\n",
    "\n",
    "# Save scalar\n",
    "filename = 'scaler.pkl'\n",
    "pickle.dump(scaler, open(filename, 'wb'))\n",
    "\n",
    "# Download the saved model file\n",
    "files.download(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ephh-ECzWyyg",
    "outputId": "ff11314c-c7c3-4630-bc61-db37e91a6069"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
      "Collecting flask-ngrok\n",
      "  Downloading flask_ngrok-0.0.25-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting flask-cors\n",
      "  Downloading Flask_Cors-5.0.0-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.5)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.8)\n",
      "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from flask-ngrok) (2.32.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (2024.12.14)\n",
      "Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
      "Downloading Flask_Cors-5.0.0-py2.py3-none-any.whl (14 kB)\n",
      "Installing collected packages: flask-ngrok, flask-cors\n",
      "Successfully installed flask-cors-5.0.0 flask-ngrok-0.0.25\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "Exception in thread Thread-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\", line 198, in _new_conn\n",
      "    sock = connection.create_connection(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/util/connection.py\", line 85, in create_connection\n",
      "    raise err\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/util/connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\", line 493, in _make_request\n",
      "    conn.request(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\", line 445, in request\n",
      "    self.endheaders()\n",
      "  File \"/usr/lib/python3.11/http/client.py\", line 1298, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/usr/lib/python3.11/http/client.py\", line 1058, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/usr/lib/python3.11/http/client.py\", line 996, in send\n",
      "    self.connect()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\", line 276, in connect\n",
      "    self.sock = self._new_conn()\n",
      "                ^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\", line 213, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7dcc08949510>: Failed to establish a new connection: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\", line 841, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/util/retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=4040): Max retries exceeded with url: /api/tunnels (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7dcc08949510>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 1401, in run\n",
      "    self.function(*self.args, **self.kwargs)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/flask_ngrok.py\", line 70, in start_ngrok\n",
      "    ngrok_address = _run_ngrok()\n",
      "                    ^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/flask_ngrok.py\", line 35, in _run_ngrok\n",
      "    tunnel_url = requests.get(localhost_url).text  # Get the tunnel information\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/requests/api.py\", line 73, in get\n",
      "    return request(\"get\", url, params=params, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/requests/api.py\", line 59, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/requests/adapters.py\", line 700, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=4040): Max retries exceeded with url: /api/tunnels (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7dcc08949510>: Failed to establish a new connection: [Errno 111] Connection refused'))\n"
     ]
    }
   ],
   "source": [
    "!pip install flask flask-ngrok flask-cors joblib\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_ngrok import run_with_ngrok\n",
    "from flask_cors import CORS\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)  # Allows your frontend to send requests\n",
    "run_with_ngrok(app)  # Exposes Colab API to the internet\n",
    "\n",
    "# Load your trained SVM model and scaler\n",
    "model = joblib.load(\"svm_model.pkl\")\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "\n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict():\n",
    "    try:\n",
    "        data = request.json  # Get JSON input from frontend\n",
    "        features = np.array(data[\"features\"]).reshape(1, -1)\n",
    "\n",
    "        # Standardize input features\n",
    "        features_scaled = scaler.transform(features)\n",
    "\n",
    "        # Predict (1 = FAKE, 0 = REAL)\n",
    "        prediction = model.predict(features_scaled)\n",
    "        result = \"FAKE\" if prediction[0] == 1 else \"REAL\"\n",
    "\n",
    "        return jsonify({\"prediction\": result})\n",
    "\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)})\n",
    "\n",
    "# Start Flask API\n",
    "app.run()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
